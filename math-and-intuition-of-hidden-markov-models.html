<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 22 Math and Intuition of Hidden Markov Models | Notes for CS181: Machine Learning</title>
  <meta name="description" content="This is a set of note for CS181: Machine Learning (Spring 2023)" />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 22 Math and Intuition of Hidden Markov Models | Notes for CS181: Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a set of note for CS181: Machine Learning (Spring 2023)" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 22 Math and Intuition of Hidden Markov Models | Notes for CS181: Machine Learning" />
  
  <meta name="twitter:description" content="This is a set of note for CS181: Machine Learning (Spring 2023)" />
  

<meta name="author" content="Weiwei Pan" />


<meta name="date" content="2023-05-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topic-models.html"/>
<link rel="next" href="the-intuition-of-markov-decision-processes.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> What is CS181?</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#why-is-ai-a-big-deal"><i class="fa fa-check"></i><b>2.1</b> Why Is AI a Big Deal?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#but-is-accuracy-enough"><i class="fa fa-check"></i><b>2.1.1</b> But Is Accuracy Enough?</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#what-happens-when-machine-learning-models-are-catastrophically-wrong"><i class="fa fa-check"></i><b>2.1.2</b> What Happens When Machine Learning Models are Catastrophically Wrong?</a></li>
<li class="chapter" data-level="2.1.3" data-path="intro.html"><a href="intro.html#are-machine-models-right-for-the-right-reasons"><i class="fa fa-check"></i><b>2.1.3</b> Are Machine Models Right for the Right Reasons?</a></li>
<li class="chapter" data-level="2.1.4" data-path="intro.html"><a href="intro.html#what-is-the-role-of-the-human-decision-maker"><i class="fa fa-check"></i><b>2.1.4</b> What is the Role of the Human Decision Maker?</a></li>
<li class="chapter" data-level="2.1.5" data-path="intro.html"><a href="intro.html#what-are-the-broader-impacts-of-tech"><i class="fa fa-check"></i><b>2.1.5</b> What are the Broader Impacts of Tech?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#machine-learning-is-much-more-than-accuracy"><i class="fa fa-check"></i><b>2.2</b> Machine Learning is Much More Than Accuracy</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#what-is-cs181"><i class="fa fa-check"></i><b>2.3</b> What is CS181?</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#what-we-are-offering-you"><i class="fa fa-check"></i><b>2.4</b> What We are Offering You</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#what-we-are-asking-from-you"><i class="fa fa-check"></i><b>2.5</b> What We are Asking From You</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#grading-evaluation"><i class="fa fa-check"></i><b>2.6</b> Grading &amp; Evaluation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="what-is-regression.html"><a href="what-is-regression.html"><i class="fa fa-check"></i><b>3</b> What is Regression?</a>
<ul>
<li class="chapter" data-level="3.1" data-path="what-is-regression.html"><a href="what-is-regression.html#what-is-machine-learning"><i class="fa fa-check"></i><b>3.1</b> What is Machine Learning?</a></li>
<li class="chapter" data-level="3.2" data-path="what-is-regression.html"><a href="what-is-regression.html#what-is-regression-1"><i class="fa fa-check"></i><b>3.2</b> What is Regression?</a></li>
<li class="chapter" data-level="3.3" data-path="what-is-regression.html"><a href="what-is-regression.html#almost-everything-is-linear-regression"><i class="fa fa-check"></i><b>3.3</b> (Almost) Everything is Linear Regression</a></li>
<li class="chapter" data-level="3.4" data-path="what-is-regression.html"><a href="what-is-regression.html#what-is-model-evaluation"><i class="fa fa-check"></i><b>3.4</b> What is Model Evaluation?</a></li>
<li class="chapter" data-level="3.5" data-path="what-is-regression.html"><a href="what-is-regression.html#what-is-model-critique"><i class="fa fa-check"></i><b>3.5</b> What is Model Critique?</a></li>
<li class="chapter" data-level="3.6" data-path="what-is-regression.html"><a href="what-is-regression.html#limitations-and-connections"><i class="fa fa-check"></i><b>3.6</b> Limitations and Connections</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="what-are-probablistic-and-non-probablistic-regression.html"><a href="what-are-probablistic-and-non-probablistic-regression.html"><i class="fa fa-check"></i><b>4</b> What are Probablistic and Non-Probablistic Regression?</a>
<ul>
<li class="chapter" data-level="4.1" data-path="what-are-probablistic-and-non-probablistic-regression.html"><a href="what-are-probablistic-and-non-probablistic-regression.html#what-is-probabilistic-regression"><i class="fa fa-check"></i><b>4.1</b> What is Probabilistic Regression?</a></li>
<li class="chapter" data-level="4.2" data-path="what-are-probablistic-and-non-probablistic-regression.html"><a href="what-are-probablistic-and-non-probablistic-regression.html#almost-everything-is-linear-regression-1"><i class="fa fa-check"></i><b>4.2</b> (Almost) Everything is Linear Regression</a></li>
<li class="chapter" data-level="4.3" data-path="what-are-probablistic-and-non-probablistic-regression.html"><a href="what-are-probablistic-and-non-probablistic-regression.html#the-cube-a-model-comparison-paradigm"><i class="fa fa-check"></i><b>4.3</b> The Cube: A Model Comparison Paradigm</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html"><i class="fa fa-check"></i><b>5</b> What Matters in ML Besides Prediction?</a>
<ul>
<li class="chapter" data-level="5.1" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#what-is-machine-learning-revisited"><i class="fa fa-check"></i><b>5.1</b> What is Machine Learning? Revisited</a></li>
<li class="chapter" data-level="5.2" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#what-are-we-uncertain-about"><i class="fa fa-check"></i><b>5.2</b> What Are We Uncertain About?</a></li>
<li class="chapter" data-level="5.3" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#where-is-uncertainty-coming-from"><i class="fa fa-check"></i><b>5.3</b> Where is Uncertainty Coming From?</a></li>
<li class="chapter" data-level="5.4" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#how-do-we-compute-uncertainty"><i class="fa fa-check"></i><b>5.4</b> How Do We Compute Uncertainty?</a></li>
<li class="chapter" data-level="5.5" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#mathematizing-uncertainty-starting-with-bias-and-variance"><i class="fa fa-check"></i><b>5.5</b> Mathematizing Uncertainty: Starting with Bias and Variance</a></li>
<li class="chapter" data-level="5.6" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#the-bias-variance-trade-off-in-machine-learning"><i class="fa fa-check"></i><b>5.6</b> The Bias-Variance Trade-off in Machine Learning</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="what-matters-in-ml-besides-prediction.html"><a href="what-matters-in-ml-besides-prediction.html#examples-of-the-bias-variance-trade-off"><i class="fa fa-check"></i><b>5.6.1</b> Examples of the Bias-Variance Trade-off</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="what-is-logistic-regression.html"><a href="what-is-logistic-regression.html"><i class="fa fa-check"></i><b>6</b> What is Logistic Regression?</a>
<ul>
<li class="chapter" data-level="6.1" data-path="what-is-logistic-regression.html"><a href="what-is-logistic-regression.html#logistic-regression-and-soft-classification"><i class="fa fa-check"></i><b>6.1</b> Logistic Regression and Soft-Classification</a></li>
<li class="chapter" data-level="6.2" data-path="what-is-logistic-regression.html"><a href="what-is-logistic-regression.html#logistic-regression-and-bernoulli-likelihood"><i class="fa fa-check"></i><b>6.2</b> Logistic Regression and Bernoulli Likelihood</a></li>
<li class="chapter" data-level="6.3" data-path="what-is-logistic-regression.html"><a href="what-is-logistic-regression.html#how-to-perform-maximum-likelihood-inference-for-logistic-regression"><i class="fa fa-check"></i><b>6.3</b> How to Perform Maximum Likelihood Inference for Logistic Regression</a></li>
<li class="chapter" data-level="6.4" data-path="what-is-logistic-regression.html"><a href="what-is-logistic-regression.html#how-not-to-evaluate-classifiers"><i class="fa fa-check"></i><b>6.4</b> How (Not) to Evaluate Classifiers</a></li>
<li class="chapter" data-level="6.5" data-path="what-is-logistic-regression.html"><a href="what-is-logistic-regression.html#how-to-interpret-logistic-regression"><i class="fa fa-check"></i><b>6.5</b> How to Interpret Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="how-do-we-responsibly-use-conditional-models.html"><a href="how-do-we-responsibly-use-conditional-models.html"><i class="fa fa-check"></i><b>7</b> How Do We Responsibly Use Conditional Models?</a>
<ul>
<li class="chapter" data-level="7.1" data-path="how-do-we-responsibly-use-conditional-models.html"><a href="how-do-we-responsibly-use-conditional-models.html#everything-weve-done-so-far-in-probabilistic-ml"><i class="fa fa-check"></i><b>7.1</b> Everything We’ve Done So Far in Probabilistic ML</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="case-study-responsibly-using-logistic-regression.html"><a href="case-study-responsibly-using-logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Case Study: Responsibly Using Logistic Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="case-study-responsibly-using-logistic-regression.html"><a href="case-study-responsibly-using-logistic-regression.html#case-study-machine-learning-model-for-loan-approval"><i class="fa fa-check"></i><b>8.1</b> Case Study: Machine Learning Model for Loan Approval</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="case-study-responsibly-using-logistic-regression.html"><a href="case-study-responsibly-using-logistic-regression.html#the-big-vague-question"><i class="fa fa-check"></i><b>8.1.1</b> The Big Vague Question</a></li>
<li class="chapter" data-level="8.1.2" data-path="case-study-responsibly-using-logistic-regression.html"><a href="case-study-responsibly-using-logistic-regression.html#the-concrete-and-rigorous-process-of-post-inference-analysis-of-machine-learning-models"><i class="fa fa-check"></i><b>8.1.2</b> The Concrete and Rigorous Process of Post-Inference Analysis of Machine Learning Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html"><i class="fa fa-check"></i><b>9</b> The Math of Training and Interpreting Logistic Regression Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#the-math-of-convex-optimization"><i class="fa fa-check"></i><b>9.1</b> The Math of Convex Optimization</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#convexity-of-the-logistic-regression-negative-log-likelihood"><i class="fa fa-check"></i><b>9.1.1</b> Convexity of the Logistic Regression Negative Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#important-mathy-details-of-gradient-descent"><i class="fa fa-check"></i><b>9.2</b> Important Mathy Details of Gradient Descent</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#does-it-converge"><i class="fa fa-check"></i><b>9.2.1</b> Does It Converge?</a></li>
<li class="chapter" data-level="9.2.2" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#how-quickly-can-we-get-there"><i class="fa fa-check"></i><b>9.2.2</b> How Quickly Can We Get There?</a></li>
<li class="chapter" data-level="9.2.3" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#does-it-scale"><i class="fa fa-check"></i><b>9.2.3</b> Does It Scale?</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="the-math-of-training-and-interpreting-logistic-regression-models.html"><a href="the-math-of-training-and-interpreting-logistic-regression-models.html#interpreting-a-logistic-regression-model-log-odds"><i class="fa fa-check"></i><b>9.3</b> Interpreting a Logistic Regression Model: Log-Odds</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html"><i class="fa fa-check"></i><b>10</b> What are Neural Networks?</a>
<ul>
<li class="chapter" data-level="10.1" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#neural-network-as-universal-function-approximators"><i class="fa fa-check"></i><b>10.1</b> Neural Network as Universal Function Approximators</a></li>
<li class="chapter" data-level="10.2" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#neural-networks-as-regression-on-learned-feature-map"><i class="fa fa-check"></i><b>10.2</b> Neural Networks as Regression on Learned Feature Map</a></li>
<li class="chapter" data-level="10.3" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#everything-is-a-neural-network"><i class="fa fa-check"></i><b>10.3</b> Everything is a Neural Network</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#architecture-zoo"><i class="fa fa-check"></i><b>10.3.1</b> Architecture Zoo</a></li>
<li class="chapter" data-level="10.3.2" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#chatgpt"><i class="fa fa-check"></i><b>10.3.2</b> ChatGPT</a></li>
<li class="chapter" data-level="10.3.3" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#stable-diffusion"><i class="fa fa-check"></i><b>10.3.3</b> Stable Diffusion</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#neural-network-optimization"><i class="fa fa-check"></i><b>10.4</b> Neural Network Optimization</a></li>
<li class="chapter" data-level="10.5" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#bias-variance-trade-off-for-neural-networks"><i class="fa fa-check"></i><b>10.5</b> Bias-Variance Trade-off for Neural Networks</a></li>
<li class="chapter" data-level="10.6" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#interpretation-of-neural-networks"><i class="fa fa-check"></i><b>10.6</b> Interpretation of Neural Networks</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#example-1-can-neural-network-models-make-use-of-human-concepts"><i class="fa fa-check"></i><b>10.6.1</b> Example 1: Can Neural Network Models Make Use of Human Concepts?</a></li>
<li class="chapter" data-level="10.6.2" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#example-2-can-neural-network-models-learn-to-explore-hypothetical-scenarios"><i class="fa fa-check"></i><b>10.6.2</b> Example 2: Can Neural Network Models Learn to Explore Hypothetical Scenarios?</a></li>
<li class="chapter" data-level="10.6.3" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#example-3-a-powerful-generalization-of-feature-importance-for-neural-network-models"><i class="fa fa-check"></i><b>10.6.3</b> Example 3: A Powerful Generalization of Feature Importance for Neural Network Models</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#the-difficulty-with-interpretable-machine-learning"><i class="fa fa-check"></i><b>10.7</b> The Difficulty with Interpretable Machine Learning</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#example-4-not-all-explanations-are-created-equal"><i class="fa fa-check"></i><b>10.7.1</b> Example 4: Not All Explanations are Created Equal</a></li>
<li class="chapter" data-level="10.7.2" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#example-5-explanations-can-lie"><i class="fa fa-check"></i><b>10.7.2</b> Example 5: Explanations Can Lie</a></li>
<li class="chapter" data-level="10.7.3" data-path="what-are-neural-networks.html"><a href="what-are-neural-networks.html#example-6-the-perils-of-explanations-in-socio-technical-systems"><i class="fa fa-check"></i><b>10.7.3</b> Example 6: The Perils of Explanations in Socio-Technical Systems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html"><i class="fa fa-check"></i><b>11</b> The Math and Interpretation of Neural Network Models</a>
<ul>
<li class="chapter" data-level="11.1" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#neural-networks-regression"><i class="fa fa-check"></i><b>11.1</b> Neural Networks Regression</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#why-its-hard-to-differentiate-a-neural-network"><i class="fa fa-check"></i><b>11.1.1</b> Why It’s Hard to Differentiate a Neural Network</a></li>
<li class="chapter" data-level="11.1.2" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#differentiating-neural-networks-backpropagation"><i class="fa fa-check"></i><b>11.1.2</b> Differentiating Neural Networks: Backpropagation</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#interpreting-neural-networks"><i class="fa fa-check"></i><b>11.2</b> Interpreting Neural Networks</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#example-1-can-neural-network-models-make-use-of-human-concepts-1"><i class="fa fa-check"></i><b>11.2.1</b> Example 1: Can Neural Network Models Make Use of Human Concepts?</a></li>
<li class="chapter" data-level="11.2.2" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#example-2-can-neural-network-models-learn-to-explore-hypothetical-scenarios-1"><i class="fa fa-check"></i><b>11.2.2</b> Example 2: Can Neural Network Models Learn to Explore Hypothetical Scenarios?</a></li>
<li class="chapter" data-level="11.2.3" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#example-3-a-powerful-generalization-of-feature-importance-for-neural-network-models-1"><i class="fa fa-check"></i><b>11.2.3</b> Example 3: A Powerful Generalization of Feature Importance for Neural Network Models</a></li>
<li class="chapter" data-level="11.2.4" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#example-4-the-perils-of-explanations"><i class="fa fa-check"></i><b>11.2.4</b> Example 4: The Perils of Explanations</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="the-math-and-interpretation-of-neural-network-models.html"><a href="the-math-and-interpretation-of-neural-network-models.html#neural-network-models-and-generalization"><i class="fa fa-check"></i><b>11.3</b> Neural Network Models and Generalization</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="the-math-behind-bayesian-regression.html"><a href="the-math-behind-bayesian-regression.html"><i class="fa fa-check"></i><b>12</b> The Math Behind Bayesian Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="the-math-behind-bayesian-regression.html"><a href="the-math-behind-bayesian-regression.html#bayesian-linear-regression"><i class="fa fa-check"></i><b>12.1</b> Bayesian Linear Regression</a></li>
<li class="chapter" data-level="12.2" data-path="the-math-behind-bayesian-regression.html"><a href="the-math-behind-bayesian-regression.html#bayesian-linear-regression-over-arbitrary-bases"><i class="fa fa-check"></i><b>12.2</b> Bayesian Linear Regression over Arbitrary Bases</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bayesian-modeling-framework.html"><a href="bayesian-modeling-framework.html"><i class="fa fa-check"></i><b>13</b> Bayesian Modeling Framework</a>
<ul>
<li class="chapter" data-level="13.1" data-path="bayesian-modeling-framework.html"><a href="bayesian-modeling-framework.html#components-of-machine-learning-reasoning"><i class="fa fa-check"></i><b>13.1</b> Components of Machine Learning Reasoning</a></li>
<li class="chapter" data-level="13.2" data-path="bayesian-modeling-framework.html"><a href="bayesian-modeling-framework.html#bayesian-modeling-paradigm"><i class="fa fa-check"></i><b>13.2</b> Bayesian Modeling Paradigm</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="bayesain-vs-frequentist-inference.html"><a href="bayesain-vs-frequentist-inference.html"><i class="fa fa-check"></i><b>14</b> Bayesain vs Frequentist Inference?</a>
<ul>
<li class="chapter" data-level="14.1" data-path="bayesain-vs-frequentist-inference.html"><a href="bayesain-vs-frequentist-inference.html#the-bayesian-modeling-process"><i class="fa fa-check"></i><b>14.1</b> The Bayesian Modeling Process</a></li>
<li class="chapter" data-level="14.2" data-path="bayesain-vs-frequentist-inference.html"><a href="bayesain-vs-frequentist-inference.html#bayesian-vs-frequentist-inference"><i class="fa fa-check"></i><b>14.2</b> Bayesian vs Frequentist Inference</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-math-of-posterior-inference.html"><a href="the-math-of-posterior-inference.html"><i class="fa fa-check"></i><b>15</b> The Math of Posterior Inference</a>
<ul>
<li class="chapter" data-level="15.1" data-path="the-math-of-posterior-inference.html"><a href="the-math-of-posterior-inference.html#the-bayesian-modeling-process-1"><i class="fa fa-check"></i><b>15.1</b> The Bayesian Modeling Process</a></li>
<li class="chapter" data-level="15.2" data-path="the-math-of-posterior-inference.html"><a href="the-math-of-posterior-inference.html#point-estimates-from-the-posterior"><i class="fa fa-check"></i><b>15.2</b> Point Estimates from the Posterior</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="the-math-of-posterior-inference.html"><a href="the-math-of-posterior-inference.html#comparison-of-posterior-point-estimates-and-mle"><i class="fa fa-check"></i><b>15.2.1</b> Comparison of Posterior Point Estimates and MLE</a></li>
<li class="chapter" data-level="15.2.2" data-path="the-math-of-posterior-inference.html"><a href="the-math-of-posterior-inference.html#law-of-large-numbers-for-bayesian-inference"><i class="fa fa-check"></i><b>15.2.2</b> Law of Large Numbers for Bayesian Inference</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="the-math-of-posterior-inference.html"><a href="the-math-of-posterior-inference.html#bayesian-logistic-regression"><i class="fa fa-check"></i><b>15.3</b> Bayesian Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="whats-hard-about-sampling.html"><a href="whats-hard-about-sampling.html"><i class="fa fa-check"></i><b>16</b> What’s Hard About Sampling?</a>
<ul>
<li class="chapter" data-level="16.1" data-path="whats-hard-about-sampling.html"><a href="whats-hard-about-sampling.html#bayesian-vs-frequentist-inference-1"><i class="fa fa-check"></i><b>16.1</b> Bayesian vs Frequentist Inference</a></li>
<li class="chapter" data-level="16.2" data-path="whats-hard-about-sampling.html"><a href="whats-hard-about-sampling.html#what-is-sampling-and-why-do-we-care"><i class="fa fa-check"></i><b>16.2</b> What is Sampling and Why do We Care?</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html"><i class="fa fa-check"></i><b>17</b> The Math of Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="17.1" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#pca-as-dimensionality-reduction-to-maximize-variance"><i class="fa fa-check"></i><b>17.1</b> PCA as Dimensionality Reduction to Maximize Variance</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#finding-a-single-pca-component"><i class="fa fa-check"></i><b>17.1.1</b> Finding a Single PCA Component</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#pca-as-dimensionality-reduction-to-minimize-reconstruction-loss"><i class="fa fa-check"></i><b>17.2</b> PCA as Dimensionality Reduction to Minimize Reconstruction Loss</a></li>
<li class="chapter" data-level="17.3" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#a-latent-variable-model-for-pca"><i class="fa fa-check"></i><b>17.3</b> A Latent Variable Model for PCA</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#one-principle-component"><i class="fa fa-check"></i><b>17.3.1</b> One Principle Component</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#autoencoders-and-nonlinear-pca"><i class="fa fa-check"></i><b>17.4</b> Autoencoders and Nonlinear PCA</a></li>
<li class="chapter" data-level="17.5" data-path="the-math-of-principal-component-analysis.html"><a href="the-math-of-principal-component-analysis.html#a-probabilistic-latent-variable-model-for-pca"><i class="fa fa-check"></i><b>17.5</b> A Probabilistic Latent Variable Model for PCA</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="the-math-of-expectation-maximization.html"><a href="the-math-of-expectation-maximization.html"><i class="fa fa-check"></i><b>18</b> The Math of Expectation Maximization</a></li>
<li class="chapter" data-level="19" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html"><i class="fa fa-check"></i><b>19</b> Motivation for Latent Variable Models</a>
<ul>
<li class="chapter" data-level="19.1" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#latent-variable-models"><i class="fa fa-check"></i><b>19.1</b> Latent Variable Models</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#example-gaussian-mixture-models-gmms"><i class="fa fa-check"></i><b>19.1.1</b> Example: Gaussian Mixture Models (GMMs)</a></li>
<li class="chapter" data-level="19.1.2" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#item-response-models"><i class="fa fa-check"></i><b>19.1.2</b> Item-Response Models</a></li>
<li class="chapter" data-level="19.1.3" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#example-factor-analysis-models"><i class="fa fa-check"></i><b>19.1.3</b> Example: Factor Analysis Models</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#maximum-likelihood-estimation-for-latent-variable-models-expectation-maximization"><i class="fa fa-check"></i><b>19.2</b> Maximum Likelihood Estimation for Latent Variable Models: Expectation Maximization</a></li>
<li class="chapter" data-level="19.3" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#the-expectation-maximization-algorithm"><i class="fa fa-check"></i><b>19.3</b> The Expectation Maximization Algorithm</a></li>
<li class="chapter" data-level="19.4" data-path="motivation-for-latent-variable-models.html"><a href="motivation-for-latent-variable-models.html#monotonicity-and-convergence-of-em"><i class="fa fa-check"></i><b>19.4</b> Monotonicity and Convergence of EM</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html"><i class="fa fa-check"></i><b>20</b> Review of Latent Variables, Compression and Clustering</a>
<ul>
<li class="chapter" data-level="20.0.1" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html#example-gaussian-mixture-models-gmms-1"><i class="fa fa-check"></i><b>20.0.1</b> Example: Gaussian Mixture Models (GMMs)</a></li>
<li class="chapter" data-level="20.0.2" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html#example-item-response-models"><i class="fa fa-check"></i><b>20.0.2</b> Example: Item-Response Models</a></li>
<li class="chapter" data-level="20.0.3" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html#example-factor-analysis-models-1"><i class="fa fa-check"></i><b>20.0.3</b> Example: Factor Analysis Models</a></li>
<li class="chapter" data-level="20.1" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html#pca-versus-probabilistic-pca-ppca"><i class="fa fa-check"></i><b>20.1</b> PCA Versus Probabilistic PCA (pPCA)</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html#what-to-know-about-expectation-maximization"><i class="fa fa-check"></i><b>20.1.1</b> What to Know About Expectation Maximization</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="review-of-latent-variables-compression-and-clustering.html"><a href="review-of-latent-variables-compression-and-clustering.html#non-probabilistic-clustering-versus-probabilistic-clustering"><i class="fa fa-check"></i><b>20.2</b> Non-Probabilistic Clustering Versus Probabilistic Clustering</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="topic-models.html"><a href="topic-models.html"><i class="fa fa-check"></i><b>21</b> Topic Models</a>
<ul>
<li class="chapter" data-level="21.1" data-path="topic-models.html"><a href="topic-models.html#our-first-latent-variable-model"><i class="fa fa-check"></i><b>21.1</b> Our First Latent Variable Model</a></li>
<li class="chapter" data-level="21.2" data-path="topic-models.html"><a href="topic-models.html#reasoning-about-text-corpa-using-topic-modeling"><i class="fa fa-check"></i><b>21.2</b> Reasoning About Text Corpa Using Topic Modeling</a></li>
<li class="chapter" data-level="21.3" data-path="topic-models.html"><a href="topic-models.html#our-second-latent-variable-model-plsa"><i class="fa fa-check"></i><b>21.3</b> Our Second Latent Variable Model: pLSA</a></li>
<li class="chapter" data-level="21.4" data-path="topic-models.html"><a href="topic-models.html#our-third-latent-variable-model-lda"><i class="fa fa-check"></i><b>21.4</b> Our Third Latent Variable Model: LDA</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="math-and-intuition-of-hidden-markov-models.html"><a href="math-and-intuition-of-hidden-markov-models.html"><i class="fa fa-check"></i><b>22</b> Math and Intuition of Hidden Markov Models</a>
<ul>
<li class="chapter" data-level="22.1" data-path="math-and-intuition-of-hidden-markov-models.html"><a href="math-and-intuition-of-hidden-markov-models.html#markov-models"><i class="fa fa-check"></i><b>22.1</b> Markov Models</a>
<ul>
<li class="chapter" data-level="22.1.1" data-path="math-and-intuition-of-hidden-markov-models.html"><a href="math-and-intuition-of-hidden-markov-models.html#transition-matrices-and-kernels"><i class="fa fa-check"></i><b>22.1.1</b> Transition Matrices and Kernels</a></li>
<li class="chapter" data-level="22.1.2" data-path="math-and-intuition-of-hidden-markov-models.html"><a href="math-and-intuition-of-hidden-markov-models.html#applications-of-markov-models"><i class="fa fa-check"></i><b>22.1.2</b> Applications of Markov Models</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="math-and-intuition-of-hidden-markov-models.html"><a href="math-and-intuition-of-hidden-markov-models.html#hidden-markov-models"><i class="fa fa-check"></i><b>22.2</b> Hidden Markov Models</a></li>
<li class="chapter" data-level="22.3" data-path="math-and-intuition-of-hidden-markov-models.html"><a href="math-and-intuition-of-hidden-markov-models.html#learning-and-inference-for-hmms"><i class="fa fa-check"></i><b>22.3</b> Learning and Inference for HMMs</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html"><i class="fa fa-check"></i><b>23</b> The Intuition of Markov Decision Processes</a>
<ul>
<li class="chapter" data-level="23.1" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#review-modeling-sequential-data"><i class="fa fa-check"></i><b>23.1</b> Review: Modeling Sequential Data</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#why-model-sequential-data-dynamics"><i class="fa fa-check"></i><b>23.1.1</b> Why Model Sequential Data (Dynamics)?</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#modeling-sequential-data-and-sequential-actions"><i class="fa fa-check"></i><b>23.2</b> Modeling Sequential Data and Sequential Actions</a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#describing-a-dynamic-world"><i class="fa fa-check"></i><b>23.2.1</b> Describing a Dynamic World</a></li>
<li class="chapter" data-level="23.2.2" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#acting-in-a-dynamic-world"><i class="fa fa-check"></i><b>23.2.2</b> Acting in a Dynamic World</a></li>
<li class="chapter" data-level="23.2.3" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#describing-worlds-as-mdps"><i class="fa fa-check"></i><b>23.2.3</b> Describing Worlds as MDP’s</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#modeling-sequential-decisions-planning"><i class="fa fa-check"></i><b>23.3</b> Modeling Sequential Decisions: Planning</a>
<ul>
<li class="chapter" data-level="23.3.1" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#modeling-action-choice"><i class="fa fa-check"></i><b>23.3.1</b> Modeling Action Choice</a></li>
<li class="chapter" data-level="23.3.2" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#modeling-cumulative-reward"><i class="fa fa-check"></i><b>23.3.2</b> Modeling Cumulative Reward</a></li>
<li class="chapter" data-level="23.3.3" data-path="the-intuition-of-markov-decision-processes.html"><a href="the-intuition-of-markov-decision-processes.html#planning-optimizing-action-choice-for-cumulative-reward"><i class="fa fa-check"></i><b>23.3.3</b> Planning: Optimizing Action Choice for Cumulative Reward</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes for CS181: Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="math-and-intuition-of-hidden-markov-models" class="section level1 hasAnchor" number="22">
<h1><span class="header-section-number">Chapter 22</span> Math and Intuition of Hidden Markov Models<a href="math-and-intuition-of-hidden-markov-models.html#math-and-intuition-of-hidden-markov-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><img src="https://i.imgur.com/xDR9VQd.png" /></p>
<div id="markov-models" class="section level2 hasAnchor" number="22.1">
<h2><span class="header-section-number">22.1</span> Markov Models<a href="math-and-intuition-of-hidden-markov-models.html#markov-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong><em>discrete time stochastic process</em></strong> is a sequence of random variables <span class="math inline">\(\{Z_n\}_{n\geq 0}\)</span> that takes values in the space <span class="math inline">\(\mathcal{S}\)</span>, this is called <strong><em>the state space</em></strong>. The state space can be continuous or discrete, finite or infinite. A stochastic process is a <strong><em>discrete time Markov model</em></strong>, a <strong><em>Markov chain</em></strong> or a <strong><em>Markov Process</em></strong>, if the process is given by:</p>
<p><span class="math display">\[
\begin{align}
Z_1 &amp;\sim p(Z_1)\\
Z_{n+1} | Z_{n} &amp;\sim p(Z_{n+1} | Z_{n})
\end{align}
\]</span></p>
<p>where <span class="math inline">\(p(Z_{n+1} | Z_{n})\)</span> is the probability density associated with transitioning from one time step to the next and <span class="math inline">\(p(Z_1)\)</span> is the probability density associated with the initial time step.</p>
<p><img src="https://i.imgur.com/Hhsh6R5.png" /></p>
<p>A Markov model satisfies the <strong><em>Markov property</em></strong> if <span class="math inline">\(Z_n\)</span> depends only on <span class="math inline">\(Z_{n-1}\)</span> (i.e. <span class="math inline">\(Z_n\)</span> is independent of <span class="math inline">\(Z_1, \ldots, Z_{n-2}\)</span> conditioned on <span class="math inline">\(Z_{n-1}\)</span>).</p>
<p>We will assume that <span class="math inline">\(p(X_n | X_{n-1})\)</span> is the same for all <span class="math inline">\(n\)</span>, in this case, we call this Markov chain <strong><em>stationary</em></strong>.</p>
<div id="transition-matrices-and-kernels" class="section level3 hasAnchor" number="22.1.1">
<h3><span class="header-section-number">22.1.1</span> Transition Matrices and Kernels<a href="math-and-intuition-of-hidden-markov-models.html#transition-matrices-and-kernels" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Markov property ensure that we can describe the dynamics of the entire chain by describing how the chain <strong><em>transitions</em></strong> from state <span class="math inline">\(i\)</span> to state <span class="math inline">\(j\)</span>. <strong>Why?</strong></p>
<p>If the state space is finite, then we can represent the transition from <span class="math inline">\(Z_{n-1}\)</span> to <span class="math inline">\(Z_{n}\)</span> as a <strong><em>transition matrix</em></strong> <span class="math inline">\(T\)</span>, where <span class="math inline">\(T_{ij}\)</span> is the probability of the chain transitioning from state <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>:
<span class="math display">\[
T_{ij} = \mathbb{P}[Z_n = j | Z_{n-1} = i].
\]</span></p>
<p>The transition matrix can be represented visually as a <strong><em>finite state diagram</em></strong>.</p>
<p>If the state space is <em>continuous</em>, then we can represent the transition from <span class="math inline">\(Z_{n-1}\)</span> to <span class="math inline">\(Z_{n}\)</span> as <strong><em>transition kernel pdf</em></strong>, <span class="math inline">\(T(z, z&#39;)\)</span>, representing the likelihood of transitioning from state <span class="math inline">\(Z_{n-1}=z\)</span> to state <span class="math inline">\(Z_{n} = z&#39;\)</span>. The probability of transitioning into a region <span class="math inline">\(A \subset \mathcal{S}\)</span> from state <span class="math inline">\(z\)</span> is given by</p>
<p><span class="math display">\[
\mathbb{P}[Z_n \in A | Z_{n-1} = z] = \int_{A} T(z, z&#39;) dz&#39;,
\]</span></p>
<p>such that <span class="math inline">\(\int_{\mathcal{S}} T(z, z&#39;) dz&#39; = 1\)</span>.</p>
</div>
<div id="applications-of-markov-models" class="section level3 hasAnchor" number="22.1.2">
<h3><span class="header-section-number">22.1.2</span> Applications of Markov Models<a href="math-and-intuition-of-hidden-markov-models.html#applications-of-markov-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Markov models can be used more generally to model any data of a <strong><em>sequential</em></strong> nature – data where the ordering of the observation contains information.</p>
<p>Sequential data appears in many domains:
1. biometric readings of patients in a hospital over their stay
2. gps location of autonomous machines over time
3. economic/financial indicators of a system over time
4. the samples obtained by a sampler over iterations</p>
<p>Learning how Markov model evolves over time, the <strong><em>dynamics</em></strong>, can lend insights on the mechanics of real-life systems that the model represent.</p>
<p><strong>Exercise:</strong> Give an example of a stochastic process that is not a Markov chain. Given an example of a stochastic process that is a Markov chain.</p>
<div id="example-smart-phone-market-model" class="section level4 hasAnchor" number="22.1.2.1">
<h4><span class="header-section-number">22.1.2.1</span> Example: Smart Phone Market Model<a href="math-and-intuition-of-hidden-markov-models.html#example-smart-phone-market-model" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider a simple model of the dynamics of the smart phone market, where we model the customer loyalty as follows:</p>
<p><img src="https://i.imgur.com/2zDjSEA.jpg" /></p>
<p>The transition matrix for the Markov chain is:
<span class="math display">\[
T = \left(\begin{array}{cc}0.8 &amp; 0.2\\ 0.4 &amp; 0.6 \end{array} \right)
\]</span>
In the above, the state space is <span class="math inline">\(S=\{ \text{Apple}, \text{Others}\}\)</span>. Say that the market is initially <span class="math inline">\(\pi^{(0)} = [0.7\; 0.3]\)</span>, i.e. 70% Apple. What is the market distribution in the long term?</p>
<blockquote>
<h3 id="optional-chapman-kolmogorov-equations-dynamics-as-matrix-multiplication" class="hasAnchor">(OPTIONAL) Chapman-Kolmogorov Equations: Dynamics as Matrix Multiplication<a href="math-and-intuition-of-hidden-markov-models.html#optional-chapman-kolmogorov-equations-dynamics-as-matrix-multiplication" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If the state space is finite, the probability of the <span class="math inline">\(n=2\)</span> state, given the initial <span class="math inline">\(n=0\)</span> state. can be computed by the <strong><em>Chapman-Kolmogorov equation</em></strong>:</p>
<p><span class="math display">\[
\mathbb{P}[Z_2 = j | Z_{0} = i] = \sum_{k\in \mathcal{S}} \mathbb{P}[Z_1 = k | Z_{0} = i]\mathbb{P}[Z_{2} = j|Z_{1}=k] = \sum_{k\in \mathcal{S}}T_{ik}T_{kj}
\]</span></p>
<p>We recognize <span class="math inline">\(\sum_{k\in \mathcal{S}}T_{ik}T_{kj}\)</span> as the <span class="math inline">\(ij\)</span>-the entry in the matrix <span class="math inline">\(TT\)</span>. Thus, the Chapman-Kolmogorov equation gives us that the matrix <span class="math inline">\(T^{(n)}\)</span> for a <span class="math inline">\(n\)</span>-step transition is
<span class="math display">\[
T^{(n)} = \underbrace{T\ldots T}_{\text{$n$ times}}
\]</span></p>
<p>In particular, when we have the initial distribution <span class="math inline">\(\pi^{(0)}\)</span> over states, then the unconditional distribution <span class="math inline">\(\pi^{(1)}\)</span> over the next state is given by:</p>
<p><span class="math display">\[
\mathbb{P}[Z_1 = i] = \sum_{k\in \mathcal{S}} \mathbb{P}[Z_1 = i | Z_0 = k]\mathbb{P}[Z_0 = k]
\]</span></p>
<p>That is, <span class="math inline">\(\pi^{(1)} = \pi^{(0)} T\)</span>.</p>
<p>If the state space is continuous, the likelihood of the <span class="math inline">\(n=2\)</span> state, given the initial <span class="math inline">\(n=0\)</span> state, can be computed by the <strong><em>Chapman-Kolmogorov equation</em></strong>:</p>
<p><span class="math display">\[
T^{(2)}(z, z&#39;) = \int_{\mathcal{S}}T(z, y)\, T(y, z&#39;) dy.
\]</span></p>
<p>In particular, when we have the initial distribution <span class="math inline">\(\pi^{(0)}(z)\)</span> over states, then the unconditional distribution <span class="math inline">\(\pi^{(1)}(z)\)</span> over the next state is given by:</p>
<p><span class="math display">\[
\pi^{(1)}(z) = \int_{\mathcal{S}} T(y, z)\,\pi^{(0)}(y)dy.
\]</span></p>
</blockquote>
</div>
</div>
</div>
<div id="hidden-markov-models" class="section level2 hasAnchor" number="22.2">
<h2><span class="header-section-number">22.2</span> Hidden Markov Models<a href="math-and-intuition-of-hidden-markov-models.html#hidden-markov-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The problem with types of sequential data observed from real-life dynamic system is that the observation is usually noisy. What we observe is not the true state of the system (e.g. the true state of the patient or the true location of the robot), but some signal that is corrupted by environmental noise.</p>
<p>In a <strong><em>hidden Markov model (HMM)</em></strong>, we assume that we do not have access to the values in the underlying Markov process
<span class="math display">\[
Z_{n+1} | Z_{n} \sim p(Z_{n+1} | Z_{n}) \quad \mathbf{(state\; model)}
\]</span></p>
<p>and, instead, observe the process
<span class="math display">\[
Y_n | Z_n \sim p(Y_n | Z_n) \quad \mathbf{(observation\; model)}
\]</span>
where <span class="math inline">\(p(Y_n | Z_n)\)</span> is the probability density associated with observing <span class="math inline">\(Y_n \in \mathcal{Y}\)</span> given the latent value, <span class="math inline">\(Z_n\)</span>, of the underlying Markov process at time <span class="math inline">\(n\)</span>.</p>
<p><img src="https://i.imgur.com/wT9zmWS.png" /></p>
<p>If the state space is continuous, Hidden Markov Models are often called <strong><em>State-Space Models</em></strong>.</p>
<p>We will observe the following notational conventions:</p>
<ul>
<li>A random variable in the HMM at time index <span class="math inline">\(n\)</span> is denoted <span class="math inline">\(Z_n\)</span> or <span class="math inline">\(Y_n\)</span>.</li>
<li>A collection of random variables from time index <span class="math inline">\(n\)</span> to time index <span class="math inline">\(n + k\)</span> is denoted <span class="math inline">\(Z_{n:n+k}\)</span> or <span class="math inline">\(Y_{n:n+k}\)</span>.</li>
<li>The value of the random variable at time index <span class="math inline">\(n\)</span> is denoted <span class="math inline">\(z_n\)</span> or <span class="math inline">\(y_n\)</span>.</li>
</ul>
<div id="example-discrete-space-models" class="section level4 hasAnchor" number="22.2.0.1">
<h4><span class="header-section-number">22.2.0.1</span> Example: Discrete Space Models<a href="math-and-intuition-of-hidden-markov-models.html#example-discrete-space-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let our state and observation spaces be DNA nucleotides: A, C, G, T. The transitions and observations are then defined by <span class="math inline">\(4\times 4\)</span> matrices.</p>
<p>The state model transition matrix tells us how likely a nucleotide is to be observed given that the previous nucleotide is an A, C, G or T.</p>
<p>Since we know that in cell division, DNA can be replicated with “typos”. Thus, the observation model can capture the probability that a given nucleotide will be mistranscribed as another nucleotide.</p>
</div>
<div id="example-linear-gaussian-models" class="section level4 hasAnchor" number="22.2.0.2">
<h4><span class="header-section-number">22.2.0.2</span> Example: Linear Gaussian Models<a href="math-and-intuition-of-hidden-markov-models.html#example-linear-gaussian-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let our state and observation spaces be Euclidean, <span class="math inline">\(\mathcal{Z} = \mathbb{R}^M\)</span> and <span class="math inline">\(\mathcal{Y} = \mathbb{R}^{M&#39;}\)</span>. The transitions and observations in a <strong><em>linear Gaussian model</em></strong> are defined by linear transformations of Gaussian variables with the addition of Gaussian noise:</p>
<p><span class="math display">\[\begin{align}
&amp;Z_0 \sim \mathcal{N}(0, \Sigma)\\
&amp;Z_{n+1} = AZ_n + B + C\xi \quad \mathbf{(State\;Model)}\\
&amp;Y_{n+1} = DZ_{n+1} + E + F\epsilon \quad \mathbf{(Observation\;Model)}
\end{align}\]</span></p>
<p>where <span class="math inline">\(\xi \sim \mathcal{N}(0, \mathbf{I}_M)\)</span>, <span class="math inline">\(\epsilon \sim \mathcal{N}(0, \mathbf{I}_{M&#39;})\)</span>. Thus, the transitions and observations probability densities are:</p>
<p><span class="math display">\[\begin{align}
Z_{n+1}|Z_n &amp;\sim \mathcal{N}(AZ_n + B, CC^\top)\\
Y_{n+1} | Z_{n+1} &amp;\sim \mathcal{N}(DZ_{n+1} + E, FF^\top)
\end{align}\]</span></p>
<p>Linear Gaussian Models are widely used in target tracking and signal processing, since inference for these models are tractible (we only need to manipulate Gaussians).</p>
</div>
</div>
<div id="learning-and-inference-for-hmms" class="section level2 hasAnchor" number="22.3">
<h2><span class="header-section-number">22.3</span> Learning and Inference for HMMs<a href="math-and-intuition-of-hidden-markov-models.html#learning-and-inference-for-hmms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are a number of inference problems associated with HMMs:</p>
<ol style="list-style-type: decimal">
<li><strong>Learning</strong> - learning the dynamics of the state or observation model
<strong>Example Algorithms:</strong> Baum-Welch (i.e. Expectation Maximization)</li>
<li><strong>Inference</strong> - estimating the probability distribution over one or more of the latent variables, <span class="math inline">\(\{Z_n\}_{n\geq 1}\)</span>, given a sequence of observations, <span class="math inline">\(\{Y_n\}_{n\geq 1}\)</span>:
<ul>
<li><strong>Filtering:</strong> computing <span class="math inline">\(p(Z_n| Y_{1:n})\)</span>.
<strong>Example Algorithms:</strong> Kalman Filters, Sequential Monte Carlo</li>
<li><strong>Smoothing:</strong> computing <span class="math inline">\(p(Z_t| Y_{1:n})\)</span> where <span class="math inline">\(t &lt; n\)</span>.
<strong>Example Algorithms:</strong> Rauch-Tung-Striebel (RTS)</li>
<li><strong>Most probable explanation</strong> computing the joint distribution of all latent variables given all observations, <span class="math inline">\(p(Z_{1:n}| Y_{1:n})\)</span>. Or, alternatively, compute the most likely sequence of latent variable values given all observations:
<span class="math display">\[
z^*_{1:n} = \underset{z_{1:n}}{\mathrm{argmax}}\; p(z_{1:n} | y_{1:n})
\]</span>
<strong>Example Algorithms:</strong> Viterbi, Forward-Backward</li>
</ul></li>
</ol>
<hr />
<blockquote>
<h3 id="optional-learning-for-hmms" class="hasAnchor">(OPTIONAL) Learning for HMMs<a href="math-and-intuition-of-hidden-markov-models.html#optional-learning-for-hmms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
Given an HMM model,
<span class="math display">\[\begin{aligned}
Z_{n+1} | Z_{n} &amp;\sim p(Z_{n+1} | Z_{n}) \quad \mathbf{(state\; model)}\\
Y_n | Z_n &amp;\sim p(Y_n | Z_n) \quad \mathbf{(observation\; model)}
\end{aligned}\]</span>
<p>Suppose that <span class="math inline">\(p(Z_{n+1} | Z_{n}) = f_\theta(_{n}, \epsilon)\)</span> and <span class="math inline">\(p(Y_n | Z_n) = g_\phi(Z_{n}, \xi)\)</span> where <span class="math inline">\(f\)</span>, <span class="math inline">\(g\)</span> are functions with parameters <span class="math inline">\(\theta, \phi\)</span> and <span class="math inline">\(\epsilon\)</span> and <span class="math inline">\(\xi\)</span> are noise variables. The learning task for HMMs is to learn values for <span class="math inline">\(\theta, \phi\)</span>. We do this by maximizing the observed data log-likelihood:</p>
<p><span class="math display">\[
\theta_{\text{MLE}}, \phi_{\text{MLE}} = \mathrm{argmax}_{\theta, \phi}\log p(Y_{1:n}; \theta, \phi)
\]</span>
Typically, we maximize the observed data log-likelihood indirectly by maximizing a lower bound, the ELBO, via <strong>expectation maximization</strong>. For linear Gaussian models and discrete state and observation spaces, both the E-step and the M-step have analytical solutions.</p>
<ol style="list-style-type: decimal">
<li><p><strong>(E-step)</strong> set <span class="math inline">\(q(Z_{1:n}) = p(Z_{1:n} | Y_{1:n}; \theta^*, \phi^*)\)</span>, where <span class="math inline">\(\theta^*, \phi^*\)</span> is from the previous M-step and the posterior <span class="math inline">\(p(Z_{1:n} | Y_{1:n}; \theta^*, \phi^*)\)</span> is computed from distributions obtained by smoothing and filtering.</p></li>
<li><p><strong>(M-step)</strong> maximize the ELBO with respect to <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>, using the <span class="math inline">\(q\)</span> obtained from the E-step. Since all the distributions are Gaussians, this can be done analytically.</p></li>
</ol>
<p>See full derivations for linear Gaussian models:
1. <a href="https://web.stanford.edu/~lmackey/stats306b/doc/stats306b-spring14-lecture11_scribed.pdf">Notes on Linear Gaussian State Space Model</a>
2. <a href="http://mlg.eng.cam.ac.uk/zoubin/course04/tr-96-2.pdf">Parameter Estimation for Linear Dynamical Systems</a></p>
</blockquote>
<blockquote>
<h3 id="optional-filtering-for-hmms-infering-pz_n-y_1n" class="hasAnchor">(OPTIONAL) Filtering for HMMs: Infering <span class="math inline">\(p(Z_n| Y_{1:n})\)</span><a href="math-and-intuition-of-hidden-markov-models.html#optional-filtering-for-hmms-infering-pz_n-y_1n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We make the following <strong>simplifying assumptions</strong>:</p>
<ol start="0" style="list-style-type: decimal">
<li>we know the model parameters, i.e. we know the parameters in the distribution <span class="math inline">\(p(Z_0)\)</span>, <span class="math inline">\(p(Z_{n+1} | Z_{n})\)</span> and <span class="math inline">\(p(Y_n | Z_n)\)</span>.</li>
<li>the underlying Markov process is homogeneous, that is, the transition probability density function is stationary. That is, for all <span class="math inline">\(n\geq 0\)</span>, we have
<span class="math display">\[
p(Y_n | Z_n) = p(Y_{n+1} | Z_{n+1}).
\]</span></li>
<li>given <span class="math inline">\(\{Z_n\}_{n\geq 0}\)</span>, the observations <span class="math inline">\(\{Y_n\}_{n\geq 0}\)</span> are independent.</li>
</ol>
<p>By Baye’s Rule, the posterior marginal distribution <span class="math inline">\(p(Z_n| Y_{1:n})\)</span> is given by
<span class="math display">\[
p(_n| Y_{1:n}) = \frac{p(Y_n | Z_n) p(Z_n | Y_{1:n-1})}{p(Y_n | Y_{1:n-1})}.
\]</span>
Note that in the above <span class="math inline">\(p(Y_n | Z_n)\)</span> is known; it is just the likelihood (distribution of the observed value given the latent state).</p>
<p>Given <span class="math inline">\(p(Z_{n-1} | Y_{1:n-1})\)</span>, we can compute the unknown term <span class="math inline">\(p(Z_n | Y_{1:n-1})\)</span> in the numerator:
<span class="math display">\[
p(Z_n | Y_{1:n-1}) = \int p(Z_n | Z_{n-1}) p(Z_{n-1} | Y_{1:n-1}) dZ_{n-1}.
\]</span>
Given <span class="math inline">\(p(Z_{n-1} | Y_{1:n-1})\)</span>, we can also compute the denominator <span class="math inline">\(p(Y_n | Y_{1:n-1})\)</span>:
<span class="math display">\[
p(Y_n | Y_{1:n-1}) = \int p(Z_{n-1} | Y_{1:n-1}) p(Z_n | Z_{n-1}) p(Y_n | Z_n) dZ_{n-1:n}.
\]</span>
Note that <span class="math inline">\(p(Z_n | Z_{n-1})\)</span> is known, it is the transition between latent states.
#### Inducitive Algorithm for Inference</p>
<p>Notice that given <span class="math inline">\(p(Z_{n-1} | Y_{1:n-1})\)</span>, we can compute <span class="math inline">\(p(Z_n| Y_{1:n}) = \frac{p(Y_n | Z_n) p(Z_n | Y_{1:n-1})}{p(Y_n | Y_{1:n-1})}\)</span>. This leads to the following inducitive algorithm for infering <span class="math inline">\(p(Z_n| Y_{1:n})\)</span>:</p>
<ol start="0" style="list-style-type: decimal">
<li>(<strong>Inductive Hypothesis</strong>) suppose we have <span class="math inline">\(p(Z_{n-1} | Y_{1:n-1})\)</span></li>
<li>(<strong>Prediction step</strong>) compute <span class="math inline">\(p(Z_n | Y_{1:n-1}) = \int p(Z_n|Z_{n-1})p(Z_{n-1}|Y_{1:n-1})dZ_{n-1}\)</span></li>
<li>(<strong>Update step</strong>) compute <span class="math inline">\(p(Z_n| Y_{1:n}) =\frac{p(Y_n|Z_n)p(Z_n|Y_{1:n-1})}{p(Y_n | Y_{1:n-1})}\)</span>, where <span class="math display">\[p(Y_n | Y_{1:n-1}) = \int p(Z_{n-1} | Y_{1:n-1}) p(X_n | Z_{n-1}) p(Y_n | Z_n) dZ_{n-1:n}.\]</span></li>
</ol>
<p><strong>The problem:</strong> save for in very few cases, the integrals we need to compute in both the prediction and update steps are intractable!</p>
<p>In the special case of <strong>linear Gaussian models</strong>, the distributions in the prediction and update steps are Gaussian and can be computed in closed form, the resulting iterative filtering algorithm is known as the <strong><em>Kalman Filter</em></strong>.</p>
</blockquote>
<blockquote>
<h3 id="optional-smoothing-for-hmms" class="hasAnchor">(OPTIONAL) Smoothing for HMMs<a href="math-and-intuition-of-hidden-markov-models.html#optional-smoothing-for-hmms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<h4 id="recursive-algorithm-for-computing-pz_t-y_1n" class="hasAnchor">Recursive Algorithm for Computing <span class="math inline">\(p(Z_{t} | Y_{1:n})\)</span><a href="math-and-intuition-of-hidden-markov-models.html#recursive-algorithm-for-computing-pz_t-y_1n" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If we assume a <strong>linear Gaussian model</strong>, we can <strong>recursively</strong> compute <span class="math inline">\(p(Z_{t} | Y_{1:n})\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Compute <span class="math inline">\(p(Z_{n} | Y_{1:n}) = \mathcal{N}(\hat{z}_{n|n}, \hat{\sigma}^2_{n|n})\)</span> for each <span class="math inline">\(n\)</span> using a Kalman filter.</li>
<li>Compute <span class="math inline">\(p(Z_{n + 1} | Y_{1:n}) = \mathcal{N}(\hat{z}_{n+1|n}, \hat{\sigma}^2_{n+1|n})\)</span> for each <span class="math inline">\(n\)</span> using a Kalman filter.</li>
<li>(<strong>Induction Hypothesis</strong>) Suppose that <span class="math inline">\(p(_{t+1} | Y_{1:n}) = \mathcal{N}(\hat{xz}_{t+1|n} \hat{\sigma}^2_{t+1|n})\)</span>.</li>
<li>(<strong>Update</strong>) using the induction hypothesis, we first compute the conditional <span class="math inline">\(p(Z_{t} | Z_{t+1}, Y_{1:n}) = \mathcal{N}(m, s^2)\)</span>, then we integrate out <span class="math inline">\(Z_{t+1}\)</span> to get:</li>
</ol>
<p><span class="math display">\[
p(Z_{t} | Y_{1:n}) = \mathcal{N}(\hat{z}_{t|n} \hat{\sigma}^2_{t|n})
\]</span></p>
<p>This suggests a <strong>recursive</strong> algorithm.</p>
</blockquote>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topic-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-intuition-of-markov-decision-processes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/20-Math-of-HMM.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
